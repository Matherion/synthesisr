% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/deduplication_functions.R
\name{find_duplicates}
\alias{find_duplicates}
\title{Detect duplicate values}
\usage{
find_duplicates(
  data,
  group_by,
  match_function = "stringdist",
  method = "osa",
  threshold,
  to_lower = TRUE,
  rm_punctuation = TRUE
)
}
\arguments{
\item{data}{A character vector containing duplicate bibliographic entries.}

\item{group_by}{An optional vector, data.frame or list containing data to use as 'grouping' variables; that is, categories within which duplicates should be sought. Defaults to NULL, in which case all entries are compared against all others. Ignored if \code{match_function = "exact"}.}

\item{match_function}{The duplicate detection method to use; options are \code{"stringdist"} for similarity, \code{"fuzzdist"} for fuzzy matching, or \code{"exact"} for exact matches.}

\item{method}{A string indicating the method to use for fuzzdist or stringdist.}

\item{threshold}{Numeric: the cutoff threshold for stringdist or fuzzdist.}

\item{to_lower}{Logical: Should all entries should be considered in lowercase when detecting duplicates? Defaults to TRUE.}

\item{rm_punctuation}{Logical: Should punctuation should be removed when detecting duplicates? Defaults to TRUE.}
}
\value{
Returns a vector of duplicate matches and methods used.
}
\description{
Identifies duplicate bibliographic entries using different duplicate detection methods.
}
\examples{
my_df <-  data.frame(
  title = c(
    "EviAtlas: a tool for visualising evidence synthesis databases",

    "revtools: An R package to support article screening for evidence synthesis",

    "An automated approach to identifying search terms for systematic reviews using keyword co‐occurrence networks",

    "Reproducible, flexible and high‐throughput data extraction from primary literature: The metaDigitise r package",

    "eviatlas:tool for visualizing evidence synthesis databases.",

    "REVTOOLS a package to support article-screening for evidence synthsis"
  ),

  year = c("2019", "2019", "2019", "2019", NA, NA),

  authors = c("Haddaway et al", "Westgate",
              "Grames et al", "Pick et al", NA, NA)
)

# run deduplication
dups <- find_duplicates(
  my_df$title,
  match_function = "stringdist",
  rm_punctuation = TRUE,
  to_lower = TRUE
)

extract_unique_references(my_df, matches = dups)

# or, in one line:
deduplicate(my_df, "title")
}
